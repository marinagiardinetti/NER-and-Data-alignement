{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMau+ZnvkcYFfgwfqZ6OvXs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Recherche et extraction des entités nommées avec Transformers.\n","Modèle de language utilisé: (Camem)BERT."],"metadata":{"id":"drG5haLXjLWI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yt6im5rrwvfs","cellView":"form"},"outputs":[],"source":["# @title Installation des bibliothèques, connexion au Google Drive\n","\n","\"\"\"Marina Giardinetti\n","marina.giardinetti@gmail.com\n","Google Colab\n","2024\"\"\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","from transformers import pipeline\n","import re\n","import os\n","import glob\n","import pandas as pd\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n","model = AutoModelForTokenClassification.from_pretrained(\"Jean-Baptiste/camembert-ner\")\n","\n","##### Process text sample (from wikipedia)\n","\n","nlp = pipeline('ner', model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n"]},{"cell_type":"code","source":["# @title Chargement du corpus\n","liste_ner =[]\n","\n","working_dir= '/content/drive/My Drive/NER_BNF/' #@param {type:\"string\"}\n","corpus = '/content/drive/My Drive/NER_BNF/corpus2/' #@param {type:\"string\"}\n","\n","# Afficher le nombre de textes\n","\n","textes = os.listdir(corpus)\n","print('Nombre de textes chargés dans le corpus: ', len(textes))\n"],"metadata":{"id":"F3ggAvdfxQ1i","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title Recherche et extraction des entités nommées\n","for texte in glob.glob(''.join([corpus, '*.txt'])):\n","  corpus = open(texte)\n","  corpus = corpus.read()\n","\n","  res = [x for x in re.split(\"[//.|//!|//?]\", corpus) if x!=\"\"]\n","  for sentence in res:\n","    ner = nlp(sentence)\n","    liste_ner.append(ner)\n","liste_ner2 =[]\n","for el in liste_ner:\n","  for el2 in el:\n","    liste_ner2.append(el2)\n","\n","\n","df = pd.DataFrame.from_records(liste_ner2)\n","#@markdown Indiquer le taux de sureté minimal requis pour chaque entité detectée\n","taux_de_precision = 0.85 #@param {type:\"string\"}\n","\n","df_pers = df.loc[(df['entity_group'] == 'PER') & (df['score'] >= taux_de_precision)]\n","df_pers.to_excel(working_dir, 'bert_pers.xlsx')\n","\n","df_loc = df.loc[(df['entity_group'] == 'LOC') & (df['score'] >= taux_de_precision)]\n","df_loc.to_excel(working_dir, 'bert_lieux.xlsx')"],"metadata":{"id":"8oUlIJq1-y8w","cellView":"form"},"execution_count":null,"outputs":[]}]}